{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847acd88",
   "metadata": {},
   "source": [
    "Evaluate Presidio Analyzer using the Presidio Evaluator framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac0a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mattc/Desktop/presidio/presidio-research-fork\n",
      "CODE_OF_CONDUCT.md              experiment_20220807-074747.json\n",
      "LICENSE                         experiment_20220807-075704.json\n",
      "NOTICE                          experiment_20220807-075836.json\n",
      "README.md                       \u001b[34mnotebooks\u001b[m\u001b[m\n",
      "SECURITY.md                     \u001b[34mpresidio_evaluator\u001b[m\u001b[m\n",
      "VERSION                         pytest.ini\n",
      "azure-pipelines.yml             requirements.txt\n",
      "\u001b[34mdata\u001b[m\u001b[m                            requirements_all.txt\n",
      "\u001b[34mdocs\u001b[m\u001b[m                            setup.cfg\n",
      "experiment_20220807-073124.json setup.py\n",
      "experiment_20220807-073416.json \u001b[34mtests\u001b[m\u001b[m\n",
      "experiment_20220807-074044.json \u001b[34mvenv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae85cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanza and spacy_stanza are not installed\n",
      "Flair is not installed by default\n",
      "Flair is not installed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "from presidio_evaluator import InputSample\n",
    "from presidio_evaluator.evaluation import Evaluator, ModelError\n",
    "from presidio_evaluator.models import PresidioAnalyzerWrapper\n",
    "from presidio_evaluator.experiment_tracking import get_experiment_tracker\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fdd23",
   "metadata": {},
   "source": [
    "Select data for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4cbd55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model en_core_web_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input: 100%|██████████| 8/8 [00:00<00:00, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset_name = \"synth_dataset_v2.json\"\n",
    "# dataset = InputSample.read_dataset_json(f\"data/{dataset_name}\")\n",
    "# print(len(dataset))\n",
    "\n",
    "dataset_name = \"generated_size_8_date_August_07_2022.json\"\n",
    "dataset = InputSample.read_dataset_json(f\"data/{dataset_name}\")\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c164ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counter = Counter()\n",
    "for sample in dataset:\n",
    "    for tag in sample.tags:\n",
    "        entity_counter[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77aedae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per entity:\n",
      "[('O', 97), ('DATE_TIME', 30), ('PERSON', 8), ('ORGANIZATION', 1)]\n",
      "\n",
      "Example sentence:\n",
      "Full text: <b>Comparison:</b>  2020-05-27 13:16:41<br /><br />\n",
      "Spans: [Type: DATE_TIME, value: 2020-05-27 13:16:41, start: 20, end: 39]\n",
      "Tokens: <b>Comparison:</b>  2020-05-27 13:16:41<br /><br />\n",
      "Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Min and max number of tokens in dataset:\n",
      "Min: 6, Max: 25\n",
      "\n",
      "Min and max sentence length in dataset:\n",
      "Min: 40, Max: 129\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per entity:\")\n",
    "pprint(entity_counter.most_common())\n",
    "\n",
    "print(\"\\nExample sentence:\")\n",
    "print(dataset[1])\n",
    "\n",
    "print(\"\\nMin and max number of tokens in dataset:\")\n",
    "print(\n",
    "    f\"Min: {min([len(sample.tokens) for sample in dataset])}, \"\n",
    "    f\"Max: {max([len(sample.tokens) for sample in dataset])}\"\n",
    ")\n",
    "\n",
    "print(\"\\nMin and max sentence length in dataset:\")\n",
    "print(\n",
    "    f\"Min: {min([len(sample.full_text) for sample in dataset])}, \"\n",
    "    f\"Max: {max([len(sample.full_text) for sample in dataset])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6348c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full text: <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />\n",
       "Spans: [Type: DATE_TIME, value: 1989-06-24 21:44:24, start: 82, end: 101, Type: PERSON, value: Annikki Järventaus, start: 59, end: 77, Type: PERSON, value: Bence Földessi, start: 44, end: 58]\n",
       "Tokens: <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />\n",
       "Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PERSON', 'PERSON', 'PERSON', 'PERSON', 'O', 'O', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'DATE_TIME', 'O', 'O', 'O', 'O', 'O']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4c379",
   "metadata": {},
   "source": [
    "Run evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf65af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Presidio Analyzer\n",
      "Entities supported by this Presidio Analyzer instance:\n",
      "US_ITIN, US_PASSPORT, IP_ADDRESS, AU_ACN, NRP, IBAN_CODE, US_BANK_NUMBER, AU_TFN, PHONE_NUMBER, CREDIT_CARD, AU_ABN, MEDICAL_LICENSE, EMAIL_ADDRESS, UK_NHS, LOCATION, CRYPTO, US_DRIVER_LICENSE, US_SSN, DATE_TIME, PERSON, URL, AU_MEDICARE, SG_NRIC_FIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating <class 'presidio_evaluator.models.presidio_analyzer_wrapper.PresidioAnalyzerWrapper'>: 100%|██████████| 8/8 [00:00<00:00, 78.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "           DATE_TIME   O  PERSON\n",
      "DATE_TIME         28   2       0\n",
      "O                  5  92       1\n",
      "PERSON             0   2       6\n",
      "Precision and recall\n",
      "              Entity           Precision              Recall   Number of samples\n",
      "           DATE_TIME              84.85%              93.33%                  30\n",
      "              PERSON              85.71%              75.00%                   8\n",
      "                 PII              85.00%              89.47%                  38\n",
      "PII F measure: 88.83%\n",
      "saving experiment data to experiment_20220807-080215.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Presidio Analyzer\")\n",
    "\n",
    "experiment = get_experiment_tracker()\n",
    "model_name = \"Presidio Analyzer\"\n",
    "model = PresidioAnalyzerWrapper()\n",
    "\n",
    "evaluator = Evaluator(model=model)\n",
    "dataset = Evaluator.align_entity_types(\n",
    "    deepcopy(dataset), entities_mapping=PresidioAnalyzerWrapper.presidio_entities_map\n",
    ")\n",
    "\n",
    "evaluation_results = evaluator.evaluate_all(dataset)\n",
    "results = evaluator.calculate_score(evaluation_results)\n",
    "\n",
    "# update params tracking\n",
    "params = {\"dataset_name\": dataset_name, \"model_name\": model_name}\n",
    "params.update(model.to_log())\n",
    "experiment.log_parameters(params)\n",
    "experiment.log_dataset_hash(dataset)\n",
    "experiment.log_metrics(results.to_log())\n",
    "entities, confmatrix = results.to_confusion_matrix()\n",
    "experiment.log_confusion_matrix(matrix=confmatrix, labels=entities)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.DataFrame(confmatrix, columns=entities, index=entities))\n",
    "\n",
    "print(\"Precision and recall\")\n",
    "print(results)\n",
    "\n",
    "# end experiment\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f8287",
   "metadata": {},
   "source": [
    "### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd04db3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'PERSON', 'PERSON', 'O']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Electronically Signed by Matthew Chung.\"\n",
    "# sent = input(\"Enter sentence: \")\n",
    "model.predict(InputSample(full_text=sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ae9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = results.model_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819eb905",
   "metadata": {},
   "source": [
    "#### False positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4802e",
   "metadata": {},
   "source": [
    "1. Most false positive tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640037af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common false positive tokens:\n",
      "[('Petersons', 1), ('earlier', 1), ('same', 1), ('day', 1), ('1007', 1), ('hrs', 1)]\n",
      "Example sentence with each FP token:\n",
      "The procedure was performed at Petersons\n",
      "PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18.\n",
      "PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18.\n",
      "PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18.\n",
      "PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18.\n",
      "PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18.\n"
     ]
    }
   ],
   "source": [
    "ModelError.most_common_fp_tokens(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03432506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps_df = ModelError.get_fps_dataframe(errors, entity=[\"LOCATION\"])\n",
    "# fps_df[[\"full_text\", \"token\", \"prediction\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0852513",
   "metadata": {},
   "source": [
    "2. False negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afae40fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bence', 1), ('Földessi', 1)]\n",
      "Token: Bence, Annotation: PERSON, Full text: <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />\n",
      "Token: Földessi, Annotation: PERSON, Full text: <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />\n"
     ]
    }
   ],
   "source": [
    "ModelError.most_common_fn_tokens(errors, n=50, entity=[\"PERSON\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed6416",
   "metadata": {},
   "source": [
    "More FN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7abfcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_df = ModelError.get_fns_dataframe(errors, entity=[\"PERSON\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae73b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>token</th>\n",
       "      <th>annotation</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 &lt;br /&gt;&lt;br /&gt;</td>\n",
       "      <td>Bence</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 &lt;br /&gt;&lt;br /&gt;</td>\n",
       "      <td>Földessi</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            full_text  \\\n",
       "0  <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />   \n",
       "1  <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />   \n",
       "\n",
       "      token annotation prediction  \n",
       "0     Bence     PERSON          O  \n",
       "1  Földessi     PERSON          O  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns_df[[\"full_text\", \"token\", \"annotation\", \"prediction\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c8be1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All errors:\n",
      "\n",
      "type: FN, Annotation = PERSON, prediction = O, Token = Bence, Full text = <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />, Metadata = None \n",
      "\n",
      "type: FN, Annotation = PERSON, prediction = O, Token = Földessi, Full text = <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />, Metadata = None \n",
      "\n",
      "type: FN, Annotation = DATE_TIME, prediction = O, Token = 21:44:24, Full text = <br /><br /><br />Electronically signed by: Bence Földessi Annikki Järventaus DO (1989-06-24 21:44:24 <br /><br />, Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = PERSON, Token = Petersons, Full text = The procedure was performed at Petersons, Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = DATE_TIME, Token = earlier, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = DATE_TIME, Token = same, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = DATE_TIME, Token = day, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = DATE_TIME, Token = 1007, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n",
      "type: FP, Annotation = O, prediction = DATE_TIME, Token = hrs, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n",
      "type: FN, Annotation = DATE_TIME, prediction = O, Token = 01:01:18, Full text = PREVIOUS REPORT: HISTORY: Subcutaneous emphysema. Comparison chest radiograph earlier same day, 1007 hrs and 1972-07-19 01:01:18., Metadata = None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All errors:\\n\")\n",
    "[print(error, \"\\n\") for error in errors][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14687fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3268dc32af4b93d15708d32177940439fba644d562b9f45c4d30fe0d015735af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
